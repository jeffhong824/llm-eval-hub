#!/usr/bin/env python3
"""
RAGAS æŒ‡æ¨™æ¸¬è©¦è…³æœ¬

ç”¨é€”ï¼šé©—è­‰æ‰€æœ‰ RAGAS 0.3.6 æŒ‡æ¨™æ˜¯å¦æ­£ç¢ºå®‰è£å’Œå¯ç”¨

ä½¿ç”¨æ–¹å¼ï¼š
    python scripts/test_ragas_metrics.py
    
    æˆ–åœ¨ Docker å®¹å™¨å…§ï¼š
    docker exec llm-eval-hub-app-1 python3 scripts/test_ragas_metrics.py
"""

import sys
from typing import Dict, Any


def test_metric_imports() -> bool:
    """æ¸¬è©¦æ‰€æœ‰æŒ‡æ¨™æ˜¯å¦èƒ½æ­£ç¢ºå°å…¥"""
    print("=" * 60)
    print("ğŸ“¦ æ¸¬è©¦ 1: æŒ‡æ¨™å°å…¥")
    print("=" * 60)
    
    try:
        from ragas.metrics import (
            AnswerAccuracy,
            AnswerCorrectness,
            AnswerRelevancy,
            AnswerSimilarity,
            ContextPrecision,
            ContextRecall,
            ContextRelevance,
            Faithfulness,
            FactualCorrectness,
            ResponseRelevancy
        )
        print("âœ… æ‰€æœ‰æŒ‡æ¨™å°å…¥æˆåŠŸï¼\n")
        return True
    except ImportError as e:
        print(f"âŒ æŒ‡æ¨™å°å…¥å¤±æ•—: {e}\n")
        return False


def test_metric_instantiation() -> Dict[str, Any]:
    """æ¸¬è©¦æ‰€æœ‰æŒ‡æ¨™æ˜¯å¦èƒ½æ­£ç¢ºå¯¦ä¾‹åŒ–"""
    print("=" * 60)
    print("ğŸ”§ æ¸¬è©¦ 2: æŒ‡æ¨™å¯¦ä¾‹åŒ–")
    print("=" * 60)
    
    from ragas.metrics import (
        AnswerAccuracy,
        AnswerCorrectness,
        AnswerRelevancy,
        AnswerSimilarity,
        ContextPrecision,
        ContextRecall,
        ContextRelevance,
        Faithfulness,
        FactualCorrectness,
        ResponseRelevancy
    )
    
    metrics = {}
    failed = []
    
    metric_classes = {
        'answer_accuracy': AnswerAccuracy,
        'answer_correctness': AnswerCorrectness,
        'factual_correctness': FactualCorrectness,
        'context_precision': ContextPrecision,
        'context_recall': ContextRecall,
        'faithfulness': Faithfulness,
        'answer_relevancy': AnswerRelevancy,
        'answer_similarity': AnswerSimilarity,
        'context_relevance': ContextRelevance,
        'response_relevancy': ResponseRelevancy
    }
    
    for name, metric_class in metric_classes.items():
        try:
            metrics[name] = metric_class()
            print(f"  âœ… {name}: {type(metrics[name]).__name__}")
        except Exception as e:
            print(f"  âŒ {name}: {e}")
            failed.append(name)
    
    if failed:
        print(f"\nâŒ {len(failed)} å€‹æŒ‡æ¨™å¯¦ä¾‹åŒ–å¤±æ•—: {', '.join(failed)}\n")
        return {}
    else:
        print(f"\nâœ… æ‰€æœ‰ {len(metrics)} å€‹æŒ‡æ¨™å¯¦ä¾‹åŒ–æˆåŠŸï¼\n")
        return metrics


def test_ragas_version() -> str:
    """æ¸¬è©¦ RAGAS ç‰ˆæœ¬"""
    print("=" * 60)
    print("ğŸ“Œ æ¸¬è©¦ 3: RAGAS ç‰ˆæœ¬")
    print("=" * 60)
    
    try:
        import ragas
        version = ragas.__version__ if hasattr(ragas, '__version__') else "Unknown"
        print(f"  RAGAS ç‰ˆæœ¬: {version}")
        
        if version.startswith('0.3') or version.startswith('0.2'):
            print(f"  âœ… ç‰ˆæœ¬ç¬¦åˆè¦æ±‚ (>= 0.2.0)\n")
            return version
        else:
            print(f"  âš ï¸  ç‰ˆæœ¬å¯èƒ½éèˆŠï¼Œå»ºè­°å‡ç´šåˆ° >= 0.2.0\n")
            return version
    except Exception as e:
        print(f"  âŒ ç„¡æ³•ç²å–ç‰ˆæœ¬: {e}\n")
        return "Unknown"


def test_dependencies() -> bool:
    """æ¸¬è©¦ç›¸é—œä¾è³´æ˜¯å¦æ­£ç¢ºå®‰è£"""
    print("=" * 60)
    print("ğŸ“š æ¸¬è©¦ 4: ç›¸é—œä¾è³´")
    print("=" * 60)
    
    dependencies = {
        'langchain': None,
        'langchain_openai': None,
        'langchain_community': None,
        'datasets': None,
        'anthropic': None,
        'openai': None
    }
    
    all_ok = True
    
    for dep in dependencies:
        try:
            module = __import__(dep)
            version = getattr(module, '__version__', 'Unknown')
            dependencies[dep] = version
            print(f"  âœ… {dep}: {version}")
        except ImportError:
            print(f"  âŒ {dep}: æœªå®‰è£")
            dependencies[dep] = None
            all_ok = False
    
    if all_ok:
        print("\nâœ… æ‰€æœ‰ä¾è³´éƒ½å·²æ­£ç¢ºå®‰è£ï¼\n")
    else:
        print("\nâš ï¸  éƒ¨åˆ†ä¾è³´ç¼ºå¤±ï¼Œå¯èƒ½å½±éŸ¿åŠŸèƒ½\n")
    
    return all_ok


def print_summary(results: Dict[str, Any]):
    """æ‰“å°æ¸¬è©¦ç¸½çµ"""
    print("=" * 60)
    print("ğŸ“Š æ¸¬è©¦ç¸½çµ")
    print("=" * 60)
    
    total_tests = 4
    passed_tests = sum([
        results['imports'],
        bool(results['instances']),
        bool(results['version']),
        results['dependencies']
    ])
    
    print(f"\nç¸½æ¸¬è©¦æ•¸: {total_tests}")
    print(f"é€šéæ¸¬è©¦: {passed_tests}")
    print(f"å¤±æ•—æ¸¬è©¦: {total_tests - passed_tests}")
    
    if passed_tests == total_tests:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼RAGAS 0.3.6 å·²æ­£ç¢ºå®‰è£ä¸¦å¯ç”¨ã€‚")
        print("\nâœ… å¯ç”¨çš„è©•ä¼°æŒ‡æ¨™:")
        for i, name in enumerate(results['instances'].keys(), 1):
            print(f"  {i}. {name}")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä¸Šè¿°éŒ¯èª¤ä¿¡æ¯ã€‚")
        return 1


def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "=" * 60)
    print("ğŸ§ª RAGAS 0.3.6 æŒ‡æ¨™æ¸¬è©¦")
    print("=" * 60 + "\n")
    
    results = {
        'imports': False,
        'instances': {},
        'version': None,
        'dependencies': False
    }
    
    # åŸ·è¡Œæ¸¬è©¦
    results['imports'] = test_metric_imports()
    
    if results['imports']:
        results['instances'] = test_metric_instantiation()
    
    results['version'] = test_ragas_version()
    results['dependencies'] = test_dependencies()
    
    # æ‰“å°ç¸½çµ
    exit_code = print_summary(results)
    
    print("\n" + "=" * 60)
    print("æ¸¬è©¦å®Œæˆ")
    print("=" * 60 + "\n")
    
    sys.exit(exit_code)


if __name__ == "__main__":
    main()

